{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In order to successfully complete this assignment you need to participate both individually and in groups during class on **Monday March 11th**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-Class Assignment: CUDA Memory and Tiling\n",
    "\n",
    "<img src=\"https://www.appianimosaic.com/uploads/2016-6-24/1920-300/per_downolad_2n.jpg\">\n",
    "<p style=\"text-align: right;\">Image from: https://www.appianimosaic.com/</p>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda for today's class (70 minutes)\n",
    "\n",
    "</p>\n",
    "\n",
    "1. (20 minutes) HW4 Review\n",
    "2. (10 minutes) Pre-class Review \n",
    "1. (10 minutes) Jupyterhub test\n",
    "3. (30 minutes) Tile Example\n",
    "4. (0 minutes) 2D wave Cuda Code Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# 1. HW4 Review\n",
    "\n",
    "\n",
    "[0301-HW4-Image_processing](0301-HW4-Image_processing.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Pre-class Review \n",
    "\n",
    "[0310--CUDA_Memory-pre-class-assignment](0310--CUDA_Memory-pre-class-assignment.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Jupyterhub Test\n",
    "\n",
    "As a class lets try to access the GPU jupyterhub server:\n",
    "\n",
    "https://jupyterhub-gpu.egr.msu.edu\n",
    "\n",
    "Upload this file to your server account and lets run class from there.  Note any odd behaviors to the instructor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "\n",
    "# 3. Tile example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tiled_transpose.cu\n",
    "\n",
    "#include <iostream>\n",
    "#include <cuda.h>\n",
    "#include <chrono>\n",
    "#define CUDA_CALL(x) {cudaError_t cuda_error__ = (x); if (cuda_error__) { fprintf(stderr, \"CUDA error: \" #x \" returned \\\"%s\\\"\\n\", cudaGetErrorString(cuda_error__)); fflush(stderr); exit(cuda_error__); } }\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "const int BLOCKDIM = 32; \n",
    "\n",
    "__global__ void transpose(const double *in_d, double * out_d, int row, int col)\n",
    "{\n",
    "   int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "   int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "   if (x < col && y < row) \n",
    "       out_d[y+col*x] = in_d[x+row*y];\n",
    "}\n",
    "\n",
    "__global__ void tiled_transpose(const double *in_d, double * out_d, int row, int col)\n",
    "{\n",
    "   int x = blockIdx.x * BLOCKDIM + threadIdx.x;\n",
    "   int y = blockIdx.y * BLOCKDIM + threadIdx.y;\n",
    "    \n",
    "   int x2 = blockIdx.y * BLOCKDIM + threadIdx.x;\n",
    "   int y2 = blockIdx.x * BLOCKDIM + threadIdx.y;\n",
    "    \n",
    "   __shared__ double in_local[BLOCKDIM][BLOCKDIM];\n",
    "   __shared__ double out_local[BLOCKDIM][BLOCKDIM];\n",
    "\n",
    "   if (x < col && y < row) {\n",
    "       in_local[threadIdx.x][threadIdx.y] = in_d[x+row*y];\n",
    "       __syncthreads();\n",
    "\n",
    "       out_local[threadIdx.y][threadIdx.x] = in_local[threadIdx.x][threadIdx.y];\n",
    "       __syncthreads();\n",
    "\n",
    "       out_d[x2+col*y2] = out_local[threadIdx.x][threadIdx.y];\n",
    "   }\n",
    "}\n",
    "\n",
    "__global__ void transpose_symmetric(double *in_d, double * out_d, int row, int col)\n",
    "{\n",
    "   int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "   int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "   if (x < col && y < row) {\n",
    "       if (x < y) { \n",
    "           double temp =  in_d[y+col*x];\n",
    "           in_d[y+col*x] = in_d[x+row*y];\n",
    "           in_d[x+row*y] = temp;\n",
    "       }\n",
    "   }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "int main(int argc,char **argv)\n",
    "{\n",
    "    std::cout << \"Begin\\n\";\n",
    "   int sz_x=BLOCKDIM*300;\n",
    "   int sz_y=BLOCKDIM*300;\n",
    "   int nBytes = sz_x*sz_y*sizeof(double);\n",
    "   int block_size = BLOCKDIM;\n",
    "   double *m_h = (double *)malloc(nBytes);\n",
    "   double * in_d;\n",
    "   double * out_d;\n",
    "   int count = 0;\n",
    "   for (int i=0; i < sz_x*sz_y; i++){\n",
    "       m_h[i] = count;\n",
    "       count++;\n",
    "   }\n",
    "   std::cout << \"Allocating device memory on host..\\n\";\n",
    "   CUDA_CALL(cudaMalloc((void **)&in_d,nBytes));\n",
    "   CUDA_CALL(cudaMalloc((void **)&out_d,nBytes));\n",
    "\n",
    "   //Set up blocks\n",
    "   dim3 dimBlock(block_size,block_size,1);\n",
    "   dim3 dimGrid(sz_x/block_size,sz_y/block_size,1);\n",
    "\n",
    "   std::cout << \"Doing GPU Transpose\\n\";\n",
    "   CUDA_CALL(cudaMemcpy(in_d,m_h,nBytes,cudaMemcpyHostToDevice));\n",
    "    \n",
    "   auto start_d = std::chrono::high_resolution_clock::now();\n",
    "   \n",
    "    /**********************/\n",
    "   transpose<<<dimGrid,dimBlock>>>(in_d,out_d,sz_y,sz_x);\n",
    "   //tiled_transpose<<<dimGrid,dimBlock>>>(in_d,out_d,sz_y,sz_x);\n",
    "\n",
    "   cudaError_t err = cudaGetLastError();\n",
    "   if (err != cudaSuccess) {\n",
    "        fprintf(stderr, \"\\n\\nError: %s\\n\\n\", cudaGetErrorString(err)); fflush(stderr); exit(err);   \n",
    "   } \n",
    "   CUDA_CALL(cudaMemcpy(m_h,out_d,nBytes,cudaMemcpyDeviceToHost));\n",
    "   /************************/\n",
    "    \n",
    "   /**********************\n",
    "   transpose_symmetric<<<dimGrid,dimBlock>>>(in_d,out_d,sz_y,sz_x);    \n",
    "   cudaError_t err = cudaGetLastError();\n",
    "   if (err != cudaSuccess) {\n",
    "        fprintf(stderr, \"\\n\\nError: %s\\n\\n\", cudaGetErrorString(err)); fflush(stderr); exit(err);   \n",
    "   } \n",
    "   CUDA_CALL(cudaMemcpy(m_h,in_d,nBytes,cudaMemcpyDeviceToHost));\n",
    "   ************************/\n",
    "    \n",
    "   auto end_d = std::chrono::high_resolution_clock::now();\n",
    "\n",
    "   std::cout << \"Doing CPU Transpose\\n\";\n",
    "   auto start_h = std::chrono::high_resolution_clock::now();\n",
    "   for (int y=0; y < sz_y; y++){\n",
    "        for (int x=y; x < sz_x; x++){\n",
    "           double temp = m_h[x+sz_x*y];\n",
    "           //std::cout << temp << \" \";\n",
    "           m_h[x+sz_x*y] = m_h[y+sz_y*x];\n",
    "           m_h[y+sz_y*x] = temp;\n",
    "       }\n",
    "       //std::cout << \"\\n\";\n",
    "   }\n",
    "   auto end_h = std::chrono::high_resolution_clock::now();\n",
    "\n",
    "\n",
    "   //Checking errors (should be same values as start)\n",
    "   count = 0;\n",
    "   int errors = 0;\n",
    "   for (int i=0; i < sz_x*sz_y; i++){\n",
    "       if (m_h[i] != count)\n",
    "           errors++;\n",
    "       count++;\n",
    "   }\n",
    "   std::cout << errors << \" Errors found in transpose\\n\";\n",
    "\n",
    "    //Print Timing\n",
    "   std::chrono::duration<double> time_d = end_d - start_d;\n",
    "   std::cout << \"Device time: \" << time_d.count() << \" s\\n\";\n",
    "   std::chrono::duration<double> time_h = end_h - start_h;\n",
    "   std::cout << \"Host time: \" << time_h.count() << \" s\\n\";\n",
    "\n",
    "   cudaFree(in_d);\n",
    "   cudaFree(out_d);\n",
    "   return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile Cuda\n",
    "!nvcc -std=c++11 -o tiled_transpose tiled_transpose.cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Run Example\n",
    "!./tiled_transpose "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# 4. 1D wave Cuda Code Optimization\n",
    "\n",
    "As a group, lets see if we can optimize the code code from lasttime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile wave_cuda.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "#include <cuda.h>\n",
    "#define CUDA_CALL(x) {cudaError_t cuda_error__ = (x); if (cuda_error__) printf(\"CUDA error: \" #x \" returned \\\"%s\\\"\\n\", cudaGetErrorString(cuda_error__));}\n",
    "\n",
    "\n",
    "__global__ void accel_update(double* d_dvdt, double* d_y, int nx, double dx2inv)\n",
    "{\n",
    "        int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "        if (i > 0 && i < nx-1)\n",
    "            d_dvdt[i]=(d_y[i+1]+d_y[i-1]-2.0*d_y[i])*(dx2inv);\n",
    "        else\n",
    "            d_dvdt[i] = 0;\n",
    "}\n",
    "\n",
    "__global__ void pos_update(double * d_dvdt, double * d_y, double * d_v, double dt)\n",
    "{\n",
    "        int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "        d_v[i] = d_v[i] + dt*d_dvdt[i];\n",
    "        d_y[i]  = d_y[i] + dt*d_v[i];\n",
    "}\n",
    "\n",
    "\n",
    "int main(int argc, char ** argv) {\n",
    "    int nx = 5000;\n",
    "    int nt = 1000000;\n",
    "    int i,it;\n",
    "    double x[nx];\n",
    "    double y[nx];\n",
    "    double v[nx];\n",
    "    double dvdt[nx];\n",
    "    double dt;\n",
    "    double dx;\n",
    "    double max,min;\n",
    "    double dx2inv;\n",
    "    double tmax;\n",
    "\n",
    "    double *d_x, *d_y, *d_v, *d_dvdt;\n",
    "    CUDA_CALL(cudaMalloc((void **)&d_x,nx*sizeof(double)));\n",
    "    CUDA_CALL(cudaMalloc((void **)&d_y,nx*sizeof(double)));\n",
    "    CUDA_CALL(cudaMalloc((void **)&d_v,nx*sizeof(double)));\n",
    "    CUDA_CALL(cudaMalloc((void **)&d_dvdt,nx*sizeof(double)));\n",
    "\n",
    "    max=10.0;\n",
    "    min=0.0;\n",
    "    dx = (max-min)/(double)(nx-1);\n",
    "    x[0] = min;\n",
    "    for(i=1;i<nx-1;i++) {\n",
    "        x[i] = min+(double)i*dx;\n",
    "    }\n",
    "\n",
    "    x[nx-1] = max;\n",
    "    tmax=10.0;\n",
    "    dt= (tmax-0.0)/(double)(nt-1);\n",
    "\n",
    "    for (i=0;i<nx;i++)  {\n",
    "        y[i] = exp(-(x[i]-5.0)*(x[i]-5.0));\n",
    "        v[i] = 0.0;\n",
    "        dvdt[i] = 0.0;\n",
    "    }\n",
    "\n",
    "   CUDA_CALL(cudaMemcpy(d_x,x,nx*sizeof(double),cudaMemcpyHostToDevice));\n",
    "   CUDA_CALL(cudaMemcpy(d_y,y,nx*sizeof(double),cudaMemcpyHostToDevice));\n",
    "   CUDA_CALL(cudaMemcpy(d_v,v,nx*sizeof(double),cudaMemcpyHostToDevice));\n",
    "   CUDA_CALL(cudaMemcpy(d_dvdt,dvdt,nx*sizeof(double),cudaMemcpyHostToDevice));\n",
    "\n",
    "   dx2inv=1.0/(dx*dx);\n",
    "   int block_size=1024;\n",
    "   int block_no = nx/block_size;\n",
    "   dim3 dimBlock(block_size,1,1);\n",
    "   dim3 dimGrid(block_no,1,1);\n",
    "\n",
    "    for(it=0;it<nt-1;it++) {\n",
    "        accel_update<<<dimGrid, dimBlock>>>(d_dvdt, d_y, nx, dx2inv);\n",
    "        pos_update<<<dimGrid, dimBlock>>>(d_dvdt, d_y, d_v, dt);\n",
    "    }\n",
    "\n",
    "   CUDA_CALL(cudaMemcpy(x,d_x,nx*sizeof(double),cudaMemcpyDeviceToHost));\n",
    "   CUDA_CALL(cudaMemcpy(y,d_y,nx*sizeof(double),cudaMemcpyDeviceToHost));\n",
    "\n",
    "    for(i=nx/2-10; i<nx/2+10; i++) {\n",
    "        printf(\"%g %g\\n\",x[i],y[i]);\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -std=c++11 -o wave_cuda wave_cuda.cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!./wave_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Congratulations, we're done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Course Resources:**\n",
    "- [Syllabus](https://tinyurl.com/y75cnzam)\n",
    "- [Preliminary Schedule](https://tinyurl.com/CMSE314-Schedule)\n",
    "- [Git Repository](https://gitlab.msu.edu/colbrydi/cmse401-s19)\n",
    "- [Jargon Jar and Command History](https://tinyurl.com/CMSE314-JargonJar) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#169; Copyright 2019,  Michigan State University Board of Trustees"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
